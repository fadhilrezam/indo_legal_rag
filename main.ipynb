{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watusi Legal Insight\n",
    "\n",
    "### Your First STop for Legal Clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install chromadb\n",
    "# !pip install ragas\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "import os\n",
    "import regex as re\n",
    "from datetime import datetime\n",
    "from typing import TypedDict, List, Dict, Annotated\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import NotRequired\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain.schema import Document\n",
    "from langchain_core.messages import AIMessage,HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder)\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "from langchain_chroma import Chroma\n",
    "import chromadb\n",
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_community.document_compressors import JinaRerank\n",
    "from mistralai import Mistral\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "import uuid\n",
    "\n",
    "#rag evaluation's library\n",
    "import random\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents and Convert to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'documents'\n",
    "\n",
    "noise_patterns = [\n",
    "    r'www\\.hukumonline\\.com',\n",
    "    r'\\nMenemukan kesalahan ketik dalam dokumen\\?\\nKlik di sini\\nuntuk perbaikan.'\n",
    "]\n",
    "# pattern = r'(www\\.hukumonline\\.com|\\nMenemukan kesalahan ketik dalam dokumen\\?\\nKlik di sini\\nuntuk perbaikan.)'\n",
    "all_docs = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.pdf'):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        loader = PyPDFLoader(file_path)\n",
    "        docs = loader.load()\n",
    "        for doc in docs:\n",
    "            for noise in noise_patterns:\n",
    "                doc.page_content = re.sub(noise, '', doc.page_content)\n",
    "        \n",
    "        all_docs.extend(docs)\n",
    "\n",
    "full_text = ''.join(page.page_content for page in all_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse The Document into Customize Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_buku = []\n",
    "list_bab = []\n",
    "docs = []\n",
    "buku_chunks = re.split(r'(?=BUKU\\s+KE\\w+)', full_text)\n",
    "for buku in buku_chunks:\n",
    "    buku_pattern = r'(BUKU\\s+KE\\w+\\s)([\\s\\S]*)'\n",
    "    buku_match = re.search(buku_pattern, buku, re.DOTALL)\n",
    "    # if not re.search(buku_pattern, buku, re.DOTALL):\n",
    "    if not buku_match:\n",
    "        continue\n",
    "    list_buku.append(buku_match.group(1).strip())\n",
    "    bab_chunks = re.split(r'(?=BAB\\s+[IVXLCDM]+)', buku)\n",
    "    for bab in bab_chunks:\n",
    "        bab_pattern =  r'(BAB\\s+[IVXLCDM]+[A-Z]?)\\s*\\n(.*)\\s*\\n([\\s\\S]*)' \n",
    "        bab_match = re.search(bab_pattern, bab)\n",
    "        # bab_pattern =  r'(BAB\\s+[IVXLCDM]+)\\s*\\n(.*)\\s*\\n(.*)'\n",
    "        # bab_match = re.search(bab_pattern, bab, re.DOTALL)\n",
    "        if not bab_match:\n",
    "            continue\n",
    "        bab_number = bab_match.group(1).strip()\n",
    "        bab_title = bab_match.group(2).strip().replace('\\n','')\n",
    "        bab_content = bab_match.group(3).strip()\n",
    "\n",
    "        # print(f'{buku_match.group(1)} -> {bab_number}, {bab_title}')\n",
    "\n",
    "        # Proses pasal pasal yang ada di level \"BAB\"\n",
    "        if 'BAGIAN' in bab:\n",
    "            before_bagian = re.split(r'(?=BAGIAN\\s+[0-9]+)', bab)[0]\n",
    "        \n",
    "        else:\n",
    "            before_bagian = bab\n",
    "        pasal_chunks = re.split(r'(?=Pasal\\s+[0-9]+[a-z]?)',before_bagian)\n",
    "        for pasal in pasal_chunks:\n",
    "            pasal_pattern = r'(Pasal\\s+[0-9]+[a-z]?)\\s*\\n(.*)'\n",
    "            pasal_match = re.search(pasal_pattern, pasal, re.DOTALL)\n",
    "            if not pasal_match:\n",
    "                continue\n",
    "            pasal_number = pasal_match.group(1).lower().replace('pasal','').strip()\n",
    "            pasal_content = pasal_match.group(2).lower().replace('\\n','').strip()\n",
    "            \n",
    "            doc = Document(\n",
    "                        page_content =\n",
    "                            f\"Bab: {bab_number} - {bab_title}\\n\"\n",
    "                            f\"Pasal: {pasal_number}\\n\"\n",
    "                            f\"Isi Pasal: {pasal_content}\",\n",
    "                        metadata = {\n",
    "                        'document_type': 'legal_document',\n",
    "                        'document_title': buku_match.group(1),\n",
    "                        'bab_number': bab_number,\n",
    "                        'bab_title': bab_title,\n",
    "                        'bagian': '',\n",
    "                        'bagian_title': '',\n",
    "                        'pasal': pasal_number})\n",
    "            docs.append(doc)\n",
    "\n",
    "            print(f'{buku_match.group(1)} -> {bab_number}, {bab_title} -> {pasal_number}')\n",
    "\n",
    "        #Proses pasal pasal yang ada di level \"BAGIAN\"\n",
    "        if 'BAGIAN' in bab:\n",
    "            bagian_chunks = re.split(r'(?=BAGIAN\\s+[0-9]+)', bab)\n",
    "            for bagian in bagian_chunks:\n",
    "                bagian_pattern = r'(BAGIAN\\s+[0-9]+)\\s*\\n*(.*)\\s+([\\s\\S]+)'\n",
    "                bagian_match = re.search(bagian_pattern, bagian)\n",
    "                # bagian_pattern = r'(BAGIAN\\s+[0-9]+)\\s*\\n*(.*)\\s+(.*)'\n",
    "                # bagian_match = re.search(bagian_pattern, bagian, re.DOTALL)\n",
    "                if not bagian_match:\n",
    "                    continue\n",
    "                bagian_number = bagian_match.group(1).strip()\n",
    "                bagian_title = bagian_match.group(2).strip().replace('\\n','')\n",
    "                # bagian_content = bagian_match.group(3).strip()\n",
    "                \n",
    "                # print(f'{buku_match.group(1)} -> {bab_number}, {bab_title} -> {bagian_number}, {bagian_title}')\n",
    "\n",
    "                pasal_chunks = re.split(r'(?=Pasal\\s+[0-9]+[a-z]?)',bagian)\n",
    "                for pasal in pasal_chunks:\n",
    "                    pasal_pattern = r'Pasal\\s+([0-9]+[a-z]?)\\s*\\n(.*)'\n",
    "                    pasal_match = re.search(pasal_pattern, pasal, re.DOTALL)\n",
    "                    if not pasal_match:\n",
    "                        continue\n",
    "                    # pasal_number = pasal_match.group(1).strip()\n",
    "                    pasal_number = pasal_match.group(1).lower().replace('pasal','').strip()\n",
    "                    pasal_content = pasal_match.group(2).lower().replace('\\n','').strip()\n",
    "                    doc = Document(\n",
    "                        page_content =\n",
    "                            f\"Bab: {bab_number} - {bab_title}\\n\"\n",
    "                            f\"Bagian: {bagian_number} - {bagian_title}\\n\"\n",
    "                            f\"Pasal: {pasal_number}\\n\"\n",
    "                            f\"Isi Pasal: {pasal_content}\",\n",
    "                        metadata = {\n",
    "                        'document_type': 'legal_document',\n",
    "                        'document_title': buku_match.group(1),\n",
    "                        'bab_number': bab_number,\n",
    "                        'bab_title': bab_title,\n",
    "                        'bagian': bagian_number,\n",
    "                        'bagian_title': bagian_title,\n",
    "                        'pasal': pasal_number})\n",
    "                    docs.append(doc)\n",
    "\n",
    "                    # print(f'{buku_match.group(1)} -> {bab_number}, {bab_title} -> {pasal_number}')\n",
    "\n",
    "\n",
    "                    # print(f'{buku_match.group(1)} -> {bab_number}, {bab_title} -> {bagian_number}, {bagian_title}')\n",
    "                # print(f'{pasal_number, pasal_content}')\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bab: BAB I - PEMBUKTIAN PADA UMUMNYA\n",
      "Pasal: 1865\n",
      "Isi Pasal: setiap orang yang mengaku mempunyai suatu hak, atau menunjuk suatu peristiwa untuk meneguhkan haknya itu atau untuk membantah suatu hak orang lain, wajib membuktikan adanya hak itu atau kejadian yang dikemukakan itu.\n"
     ]
    }
   ],
   "source": [
    "#document evaluation\n",
    "print([doc for doc in docs if doc.metadata['bab_title'] == 'PEMBUKTIAN PADA UMUMNYA'][0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed Documents, Store in Vector DB and Rerank with Cross-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load api key\n",
    "with open('credentials.json', 'r')as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "mistral_api = data['mistral_api']\n",
    "jina_api = data['jina_api']\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#load embedding model\n",
    "model_name = 'mistral-embed'\n",
    "embedding_model = MistralAIEmbeddings(\n",
    "    model = model_name,\n",
    "    api_key=mistral_api)\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#store / load document from chroma db\n",
    "vector_store = Chroma(\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory='.\\pipeline\\chroma_db',\n",
    "    collection_name = 'kuhperdata_mistral'   \n",
    ")\n",
    "# vector_store.add_documents(docs) #-> Run this script to add document to vector db\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#set vector db as retriver with search type similarity and get 'top 5' documents\n",
    "# retriever = vector_store.as_retriever(\n",
    "#     search_type = 'similarity',\n",
    "#     k= 5)\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type = 'mmr',\n",
    "    search_kwargs = {\n",
    "        'fetch_k': 10,\n",
    "        'k': 3})\n",
    "\n",
    "#rerank the documents with the help of Cross Encoder model (in my case I'm utilazing Jina Reranker model)\n",
    "compressor = JinaRerank(jina_api_key = jina_api, top_n = 2)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever)\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Run code below to identified what vector db (collection) that available in the local storage\n",
    "# client = chromadb.PersistentClient(path = './pipeline/chroma_db/')\n",
    "# client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = chromadb.PersistentClient(path = './pipeline/chroma_db/')\n",
    "# client.list_collections()\n",
    "# client.delete_collection(name = 'kuhperdata_mistral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_retrieval(retriever, query, expected_content=None):\n",
    "    \"\"\"Debug retrieval dengan eye-balling results\"\"\"\n",
    "    results = retriever.similarity_search_with_score(query, k=3)\n",
    "    \n",
    "    print(f\"Query: {query}\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, (doc, score) in enumerate(results):\n",
    "        print(f\"Rank {i+1} | Score: {score:.4f}\")\n",
    "        print(f\"Content: {doc.page_content[:200]}...\")\n",
    "        if expected_content and expected_content.lower() in doc.page_content.lower():\n",
    "            print(\"‚úÖ CONTAINS EXPECTED CONTENT!\")\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "# Test\n",
    "# debug_retrieval(vector_store, \"Pasal 1234\", \"Perikatan ditujukan untuk memberikan sesuatu, untuk berbuat sesuatu, atau untuk tidak berbuat sesuatu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LLM Model\n",
    "\n",
    "1. Mistral LLM for RAG Chain -> *gemma model as alternative with local environment*\n",
    "2. OpenRouter API to Access LLM Model (For RAG Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('credentials.json', 'r')as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "mistral_api = data['mistral_api']\n",
    "open_route_api = data['open_route_api']\n",
    "genai_api = data['google_ai_api']\n",
    "\n",
    "#load gemma model\n",
    "ollama_llm = OllamaLLM(\n",
    "    model = 'gemma3:1b',\n",
    "    temperature = 0.2)\n",
    "\n",
    "#load mistral model\n",
    "mistral_llm = ChatMistralAI(\n",
    "    # model = 'Hermes-2-Pro-Mistral-7B',\n",
    "    model = 'mistral-small-2506',\n",
    "    api_key=mistral_api,\n",
    "    temperature = 0.1\n",
    ")\n",
    "\n",
    "#load gemini model\n",
    "openrouter_llm = ChatOpenAI(\n",
    "    model = 'openai/gpt-oss-120b:free',\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key = open_route_api\n",
    ")\n",
    "\n",
    "# genai_llm = ChatGoogleGenerativeAI(\n",
    "#     model = 'gemini-2.5-flash-lite',\n",
    "#     api_key = genai_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RAG Chain Utilizing Langchain and Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "greeting_keywords = [\n",
    "# Umum\n",
    "\"halo\", \"hai\", \"hei\", \"apa kabar\", \"bagaimana kabarnya\", \"salam\",\n",
    "# Berdasarkan waktu\n",
    "\"selamat pagi\", \"selamat siang\", \"selamat sore\", \"selamat malam\", \"selamat subuh\",\n",
    "\"pagi\", \"siang\", \"sore\", \"malam\",\n",
    "\n",
    "# Gaul / Santai\n",
    "\"bro\", \"sis\", \"cuy\", \"sob\", \"gan\",\n",
    "\n",
    "# Formal / Sopan\n",
    "\"assalamu‚Äôalaikum\", \"wa‚Äôalaikumussalam\", \"salam sejahtera\",\n",
    "\"om swastiastu\", \"shalom\", \"namo buddhaya\", \"salam kebajikan\"]\n",
    "\n",
    "legal_keywords = [\n",
    "# Dasar Hukum / Aturan\n",
    "\"undang-undang\", \"uu\", \"peraturan\", \"perpu\", \"pp\", \"permen\", \"putusan\", \"putusan mahkamah\", \n",
    "\"putusan pengadilan\", \"perda\", \"perkap\", \"keputusan\", \"instruksi\", \"ketetapan\",\n",
    "\n",
    "# Pasal & Kitab Hukum\n",
    "\"pasal\", \"ayat\", \"kitab undang-undang hukum pidana\", \"kuhp\", \"kitab undang-undang hukum perdata\",\n",
    "\"kuhperdata\", \"kuhap\", \"uu ite\", \"uu perkawinan\", \"uu ketenagakerjaan\",\n",
    "\n",
    "# Proses Peradilan\n",
    "\"hakim\", \"jaksa\", \"pengacara\", \"penasihat hukum\", \"tersangka\", \"terdakwa\", \"saksi\", \"korban\",\n",
    "\"sidang\", \"peradilan\", \"putusan\", \"putusan kasasi\", \"putusan banding\", \"putusan mk\", \"putusan ma\",\n",
    "\n",
    "# Jenis Hukum\n",
    "\"hukum pidana\", \"hukum perdata\", \"hukum tata negara\", \"hukum administrasi\", \n",
    "\"hukum adat\", \"hukum islam\", \"hukum dagang\",\n",
    "\n",
    "# Istilah Kontrak / Perjanjian\n",
    "\"kontrak\", \"perjanjian\", \"akta\", \"notaris\", \"hak dan kewajiban\", \"sanksi\", \"gugatan\",\n",
    "\"wanprestasi\", \"perbuatan melawan hukum\",\n",
    "\n",
    "# Istilah Pidana Umum\n",
    "\"korupsi\", \"pencurian\", \"penggelapan\", \"penipuan\", \"pembunuhan\", \"pemerkosaan\",\n",
    "\"pencucian uang\", \"narkotika\", \"terorisme\",\n",
    "\n",
    "# Istilah Sengketa / Arbitrase\n",
    "\"sengketa\", \"arbitrase\", \"mediasi\", \"negosiasi\", \"perdamaian\", \"putusan arbitrase\"\n",
    "]\n",
    "\n",
    "followup_keywords = ['lebih detail', 'maksudnya', 'contohnya', 'jelaskan lagi', \n",
    "                        'bagaimana dengan', 'lalu', 'kemudian', 'selanjutnya']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverallState(TypedDict):\n",
    "    question: str\n",
    "    retrieved_docs: List[Document]\n",
    "    prompt: str\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    llm: object\n",
    "    nama: NotRequired[str]\n",
    "    domisili: NotRequired[str]\n",
    "    summary: NotRequired[str]\n",
    "\n",
    "def classify_query(state: OverallState) -> dict:\n",
    "    input = state['question']\n",
    "    if any(word in input.lower() for word in greeting_keywords):\n",
    "        return 'greeting'\n",
    "    # elif any(word in input.lower() for word in legal_keywords):\n",
    "    elif 'pasal' in input.lower():\n",
    "        return 'legal_specific'\n",
    "    elif any(word in input.lower() for word in followup_keywords):\n",
    "        return 'followup'\n",
    "    return 'general'\n",
    "\n",
    "\n",
    "def retriever_node(state: OverallState) -> dict:\n",
    "    question_type = classify_query(state)\n",
    "    question = state['question']\n",
    "    if question_type == 'greeting':\n",
    "        return {\n",
    "        **state,\n",
    "        'retrieved_docs': []}\n",
    "    elif question_type == 'legal_specific':\n",
    "        try:\n",
    "            matches = re.findall(r'(?i)(?<=pasal\\s*)\\d+\\s*[a-z]?\\b', question)\n",
    "            if matches:\n",
    "                docs = []\n",
    "\n",
    "                # Batch process \n",
    "                retriever_pasal = vector_store.as_retriever(\n",
    "                    search_type = 'similarity',\n",
    "                    search_kwargs = {'k':1})\n",
    "                for match in matches:\n",
    "                    pasal_key = match.replace(' ','')\n",
    "                    print(f\"üìã [RETRIEVER NODE] Processing pasal: {pasal_key}\")\n",
    "                    try:\n",
    "                        result = retriever_pasal.get_relevant_documents(pasal_key, filter = {'pasal': pasal_key})\n",
    "                        docs.extend(result)\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå [RETRIEVER NODE] Error retrieving pasal {pasal_key}: {e}\")\n",
    "\n",
    "            else:\n",
    "                print(\"üîç [RETRIEVER NODE] No pasal found\")\n",
    "                docs = []\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå [RETRIEVER NODE] Error: {e}\")\n",
    "            docs = []   \n",
    "        return {\n",
    "            **state,\n",
    "            'retrieved_docs': docs\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            **state,\n",
    "            'retrieved_docs': []\n",
    "        }\n",
    "\n",
    "def merger_node(state:OverallState) -> dict:\n",
    "    summary = state.get('summary','')\n",
    "    docs = state.get('retrieved_docs', [])\n",
    "    context = '\\n'.join([doc.page_content for doc in state['retrieved_docs']])\n",
    "    system_prompt = f\"\"\"\n",
    "    Kamu adalah seorang ahli hukum. Jawab pertanyaan user berdasarkan **Konteks berikut**:\n",
    "\n",
    "    Ringkasan Percakapan Sebelumnya:\n",
    "    {summary}\n",
    "\n",
    "    Dokumen relevan:\n",
    "    {context}\n",
    "\n",
    "    \n",
    "    ### Instruksi:\n",
    "    - Jawab selalu dalam **bahasa Indonesia** dan **output harus di bawah 50 kata**\n",
    "    - **Jawaban langsung ke inti**\n",
    "    - Jika pertanyaannya meminta isi pasal (misalnya menyebut \"Pasal 1320\", \"bunyi Pasal\", dsb), kutip isi pasal yang diminta **secara langsung** dari konteks.\n",
    "    - Jika pertanyaannya berupa kasus hukum (contoh: pelanggaran perjanjian kerja sama, wanprestasi, dll), berikan pasal **yang relevan saja** dari konteks, jangan mengarang.\n",
    "    - Jika informasi tidak ditemukan dalam konteks, katakan bahwa **informasi tidak tersedia** atau **ajukan pertanyaan untuk meminta kejelasan ke user**\n",
    "    \n",
    "    ### Deteksi Lanjutan (Sinyal Eskalasi):\n",
    "    Jika user menunjukkan salah satu dari hal berikut, barulah berikan **kontak pengacara**:\n",
    "    1. Menyatakan **bingung secara hukum**, misal: ‚ÄúSaya tidak tahu harus bagaimana‚Äù, ‚ÄúTolong bantu saya‚Äù\n",
    "    2. Menyatakan ingin **dibantu secara langsung**\n",
    "    3. Menyebut butuh bantuan **membuat/review dokumen**\n",
    "    4. Menunjukkan **keputusasaan/kebingungan yang jelas**\n",
    "    5. Menyatakan ingin **berkonsultasi lebih lanjut**\n",
    "    6. Jangan berikan tawaran bantuan hukum **di awal percakapan**\n",
    "\n",
    "    ### Jika Sinyal Terdeteksi:\n",
    "    Tambahkan di akhir jawaban:\n",
    "    \"Jika Anda membutuhkan bantuan lebih lanjut, silakan hubungi kami melalui email [Watusi Legal Insight](contact@watusilegalinsight.com) atau WhatsApp 0812-3456-7890. Tim kami akan menghubungi Anda setelah verifikasi data dilakukan.\"\n",
    "\n",
    "    **Jangan berikan kontak jika belum ada sinyal di atas.**\n",
    "    \"\"\"\n",
    "    prompt = ChatPromptTemplate([\n",
    "        ('system', system_prompt),\n",
    "        # ('human', state['question'])\n",
    "        MessagesPlaceholder(variable_name = 'messages')\n",
    "    ])\n",
    "    \n",
    "    return{\n",
    "        **state,\n",
    "        'prompt': prompt,\n",
    "        'messages': [HumanMessage(content=state['question'])]\n",
    "    }\n",
    "\n",
    "def output_node(state: OverallState) -> dict:\n",
    "    try:\n",
    "        qa_chain = state['prompt'] | state['llm']\n",
    "        result = qa_chain.invoke({'messages':state['messages']})\n",
    "\n",
    "        return {\n",
    "            **state,\n",
    "            'messages':result\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå [OUTPUT NODE] Error: {e}\")\n",
    "        error_msg = AIMessage(content=f\"Maaf, terjadi kesalahan: {str(e)}\")\n",
    "\n",
    "def summarizer_node(state: OverallState) -> dict:\n",
    "    conversation = ''\n",
    "    for msg in state['messages']:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            role = 'user'\n",
    "        else:\n",
    "            role = 'ai'\n",
    "        conversation += f\"{role}: {msg.content}\\n\\n\"\n",
    "    summarizer_prompt =f\"\"\"\n",
    "        Buat ringkasan dari {conversation}, **maksimal 50 kata**. \n",
    "        Jelaskan inti permasalahan user, apa jawaban dari AI, dan apakah ada indikasi bahwa user butuh bantuan hukum lanjutan atau tidak to the point langsung ringkas tanpa header apapun.\n",
    "        Jika user butuh bantuan dan user sudah konfirmasi, maka AI menjawab data dan permasalahan/kasus user akan di verifikasi oleh team dan akan dihubungi segera.\n",
    "        \"\"\"\n",
    "    prompt = ChatPromptTemplate([\n",
    "        ('system', summarizer_prompt)])\n",
    "    qa_chain = prompt | state['llm']\n",
    "    chat_summary = qa_chain.invoke({}).content\n",
    "    return {\n",
    "        **state,\n",
    "        'summary': chat_summary\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "builder = StateGraph(OverallState)\n",
    "builder.add_node('retriever', retriever_node)\n",
    "builder.add_node('merger', merger_node)\n",
    "builder.add_node('output', output_node)    \n",
    "builder.add_node('summarizer', summarizer_node)    \n",
    "builder.add_edge(START, 'retriever')\n",
    "builder.add_edge('retriever', 'merger')\n",
    "builder.add_edge('merger', 'output')\n",
    "builder.add_edge('output', 'summarizer')\n",
    "builder.add_edge('summarizer', END)\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\"configurable\": {\"thread_id\": thread_id}}   \n",
    "graph_memory = builder.compile(checkpointer = checkpointer)\n",
    "graph = builder.compile()\n",
    "# graph_memory = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = 'kalau gaji saya belum di bayarkan perusahaan, bisa saya kenakan pasal berapa aja, dan apa saja hak saya ?'\n",
    "# question = 'saya bingung proses hukumnya gimana'\n",
    "question = 'sudah saya hubungi via whatsapp, lalu apa ?'\n",
    "result = graph_memory.stream({'question':question, 'llm':mistral_llm}, config, stream_mode = 'values')\n",
    "# result = graph_memory.stream({'question':question, 'llm':mistral_llm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in result:\n",
    "    final_result = chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "kalau gaji saya belum di bayarkan perusahaan, bisa saya kenakan pasal berapa aja, dan apa saja hak saya ?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Untuk gaji yang belum dibayarkan, Anda bisa mengajukan tuntutan berdasarkan Pasal 1320 KUHPerdata (KKP) tentang perjanjian kerja. Hak Anda meliputi:\n",
      "1. Gaji yang belum dibayarkan.\n",
      "2. Bunga gaji (jika ada ketidakpastian waktu pembayaran).\n",
      "3. Ganti rugi jika ada kerugian tambahan.\n",
      "\n",
      "Jika Anda bingung atau membutuhkan bantuan lebih lanjut, silakan hubungi kami melalui email [Watusi Legal Insight](contact@watusilegalinsight.com) atau WhatsApp 0812-3456-7890. Tim kami akan menghubungi Anda setelah verifikasi data dilakukan.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "saya bingung proses hukumnya gimana\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Untuk proses hukum gaji yang belum dibayarkan, Anda bisa mengajukan tuntutan melalui:\n",
      "1. **Perundingan** dengan perusahaan.\n",
      "2. **Pengadilan** jika perundingan gagal.\n",
      "3. **Bantuan hukum** untuk mempersiapkan dokumen dan langkah selanjutnya.\n",
      "\n",
      "Jika Anda membutuhkan bantuan lebih lanjut, silakan hubungi kami melalui email [Watusi Legal Insight](contact@watusilegalinsight.com) atau WhatsApp 0812-3456-7890. Tim kami akan menghubungi Anda setelah verifikasi data dilakukan.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "sudah saya hubungi via whatsapp, lalu apa ?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Setelah Anda menghubungi kami via WhatsApp, tim kami akan segera merespon dan memverifikasi data Anda. Pastikan untuk menyertakan informasi lengkap seperti nama, nomor telepon, dan detail kasus Anda. Kami akan memberikan panduan lebih lanjut setelah verifikasi selesai.\n"
     ]
    }
   ],
   "source": [
    "for i in final_result['messages']:\n",
    "    i.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User bingung tentang gaji yang belum dibayarkan, termasuk pasal hukum yang berlaku dan hak-haknya. AI menjelaskan pasal KUHPerdata yang relevan dan hak-hak user, serta langkah-langkah hukum yang bisa diambil. User kemudian bertanya tentang proses hukum, dan AI menjelaskan tahapan perundingan, pengadilan, dan bantuan hukum. User sudah menghubungi via WhatsApp, dan AI menunggu verifikasi data untuk memberikan bantuan lebih lanjut. User sudah konfirmasi, maka data dan permasalahan/kasus user akan di verifikasi oleh team dan akan dihubungi segera.\n"
     ]
    }
   ],
   "source": [
    "print(final_result['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot Function to Retrieve Question (chat bot with and without memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_bot_with_memory(question:str, llm = None):\n",
    "    if llm is None:\n",
    "        llm = mistral_llm\n",
    "        final_result = None\n",
    "\n",
    "        for chunk in graph_memory.stream({'question': question, 'llm': llm}, config, stream_mode = 'values'):\n",
    "            final_result = chunk\n",
    "        for i in range(len(final_result['messages'])):\n",
    "            final_result['messages'][i].pretty_print()\n",
    "        return final_result, config['configurable']['thread_id']\n",
    "\n",
    "def chat_bot(question: str, llm = None):\n",
    "    if llm is None:\n",
    "        llm = mistral_llm\n",
    "    result = graph.invoke({'question':question, 'llm':llm})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã [RETRIEVER NODE] Processing pasal: 1234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Perikatan ditujukan untuk memberikan sesuatu, untuk berbuat sesuatu, atau untuk tidak berbuat sesuatu.'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'bunyi pasal 1234'\n",
    "result = chat_bot(question)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç [RETRIEVER NODE] No pasal found\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "kalau gaji saya belum di bayarkan perusahaan, bisa saya kenakan pasal berapa aja, dan apa saja hak saya ?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Untuk gaji yang belum dibayarkan, Anda bisa mengajukan tuntutan berdasarkan Pasal 1320 KUHPerdata (KKP) tentang perjanjian kerja. Hak Anda meliputi:\n",
      "1. Gaji yang belum dibayarkan.\n",
      "2. Bunga gaji (jika ada ketidakpastian waktu pembayaran).\n",
      "3. Ganti rugi jika ada kerugian tambahan.\n",
      "\n",
      "Jika Anda bingung atau membutuhkan bantuan lebih lanjut, silakan hubungi kami melalui email [Watusi Legal Insight](contact@watusilegalinsight.com) atau WhatsApp 0812-3456-7890. Tim kami akan menghubungi Anda setelah verifikasi data dilakukan.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "saya bingung proses hukumnya gimana\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Untuk proses hukum gaji yang belum dibayarkan, Anda bisa mengajukan tuntutan melalui:\n",
      "1. **Perundingan** dengan perusahaan.\n",
      "2. **Pengadilan** jika perundingan gagal.\n",
      "3. **Bantuan hukum** untuk mempersiapkan dokumen dan langkah selanjutnya.\n",
      "\n",
      "Jika Anda membutuhkan bantuan lebih lanjut, silakan hubungi kami melalui email [Watusi Legal Insight](contact@watusilegalinsight.com) atau WhatsApp 0812-3456-7890. Tim kami akan menghubungi Anda setelah verifikasi data dilakukan.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "sudah saya hubungi via whatsapp, lalu apa ?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Setelah Anda menghubungi kami via WhatsApp, tim kami akan segera merespon dan memverifikasi data Anda. Pastikan untuk menyertakan informasi lengkap seperti nama, nomor telepon, dan detail kasus Anda. Kami akan memberikan panduan lebih lanjut setelah verifikasi selesai.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Kantor saya tidak membayarkan upah selama 3 bulan terakhir, bisa dikenakan pasal berapa aja ?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Untuk gaji yang belum dibayarkan selama 3 bulan, Anda bisa mengajukan tuntutan berdasarkan Pasal 1320 KUHPerdata (KKP) tentang perjanjian kerja. Pasal ini mengatur tanggung jawab atas pelanggaran perjanjian.\n",
      "\n",
      "Jika Anda membutuhkan bantuan lebih lanjut, silakan hubungi kami melalui email [Watusi Legal Insight](contact@watusilegalinsight.com) atau WhatsApp 0812-3456-7890. Tim kami akan menghubungi Anda setelah verifikasi data dilakukan.\n"
     ]
    }
   ],
   "source": [
    "question = 'Kantor saya tidak membayarkan upah selama 3 bulan terakhir, bisa dikenakan pasal berapa aja ?'\n",
    "# question = 'Kalau 1602j bunyi pasalnya apa ?'\n",
    "# question = 'siapa nama saya ?'\n",
    "final_result, thread_id = chat_bot_with_memory(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rag Evaluation with RAGAS Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_inference = random.sample(docs, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã [RETRIEVER NODE] Processing pasal: 1722\n",
      "üìã [RETRIEVER NODE] Processing pasal: 1803\n",
      "üìã [RETRIEVER NODE] Processing pasal: 1764\n",
      "üìã [RETRIEVER NODE] Processing pasal: 1337\n",
      "üìã [RETRIEVER NODE] Processing pasal: 1469\n"
     ]
    }
   ],
   "source": [
    "user_inputs = []\n",
    "references = []\n",
    "\n",
    "for doc in docs_inference:\n",
    "    user_input = f\"Bunyi pasal {doc.metadata.get('pasal')} apa dan terletak pada bab dan bagian berapa jika ada?\"\n",
    "    reference = doc.page_content\n",
    "    \n",
    "    user_inputs.append(user_input)\n",
    "    references.append(reference)\n",
    "\n",
    "responses = []\n",
    "contexts = []\n",
    "\n",
    "for user_input in user_inputs:\n",
    "    result = chat_bot(user_input)\n",
    "\n",
    "    responses.append(result['messages'][-1].content) \n",
    "    contexts.append([doc.page_content for doc in result['retrieved_docs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 685.90 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data = (\n",
    "    {'user_input': user_inputs,\n",
    "    'reference': references,\n",
    "    'response': responses,\n",
    "    'retrieved_contexts': contexts\n",
    "    })\n",
    "\n",
    "dataset = Dataset.from_dict(data)\n",
    "dataset.save_to_disk('./outputs/generation/data_inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:14<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "evaluator_llm = LangchainLLMWrapper(mistral_llm)\n",
    "result = evaluate(dataset=dataset,metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],llm=evaluator_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = result.to_pandas()\n",
    "df_result.to_csv('outputs\\generation\\evaluation\\mistral_score.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_recall': 1.0000, 'faithfulness': 1.0000, 'factual_correctness(mode=f1)': 0.9340}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>factual_correctness(mode=f1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bunyi pasal 1722 apa dan terletak pada bab dan...</td>\n",
       "      <td>[Bab: BAB XI - PENITIPAN BARANG\\nBagian: BAGIA...</td>\n",
       "      <td>Bunyi Pasal 1722: \"Jika pemberi titipan bergan...</td>\n",
       "      <td>Bab: BAB XI - PENITIPAN BARANG\\nBagian: BAGIAN...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bunyi pasal 1803 apa dan terletak pada bab dan...</td>\n",
       "      <td>[Bab: BAB XVI - PEMBERIAN KUASA\\nBagian: BAGIA...</td>\n",
       "      <td>Bunyi Pasal 1803:\\nPenerima kuasa bertanggung ...</td>\n",
       "      <td>Bab: BAB XVI - PEMBERIAN KUASA\\nBagian: BAGIAN...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bunyi pasal 1764 apa dan terletak pada bab dan...</td>\n",
       "      <td>[Bab: BAB XIII - PINJAM PAKAI HABIS\\nBagian: B...</td>\n",
       "      <td>Bunyi Pasal 1764: \"Jika ia tidak mungkin memen...</td>\n",
       "      <td>Bab: BAB XIII - PINJAM PAKAI HABIS\\nBagian: BA...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bunyi pasal 1337 apa dan terletak pada bab dan...</td>\n",
       "      <td>[Bab: BAB II - PERIKATAN YANG LAHIR DARI KONTR...</td>\n",
       "      <td>Bunyi Pasal 1337: \"suatu sebab adalah terlaran...</td>\n",
       "      <td>Bab: BAB II - PERIKATAN YANG LAHIR DARI KONTRA...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bunyi pasal 1469 apa dan terletak pada bab dan...</td>\n",
       "      <td>[Bab: BAB V - JUAL BELI\\nBagian: BAGIAN 1 - Ke...</td>\n",
       "      <td>Bunyi Pasal 1469: \"Atas ancaman yang sama, par...</td>\n",
       "      <td>Bab: BAB V - JUAL BELI\\nBagian: BAGIAN 1 - Ket...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  Bunyi pasal 1722 apa dan terletak pada bab dan...   \n",
       "1  Bunyi pasal 1803 apa dan terletak pada bab dan...   \n",
       "2  Bunyi pasal 1764 apa dan terletak pada bab dan...   \n",
       "3  Bunyi pasal 1337 apa dan terletak pada bab dan...   \n",
       "4  Bunyi pasal 1469 apa dan terletak pada bab dan...   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [Bab: BAB XI - PENITIPAN BARANG\\nBagian: BAGIA...   \n",
       "1  [Bab: BAB XVI - PEMBERIAN KUASA\\nBagian: BAGIA...   \n",
       "2  [Bab: BAB XIII - PINJAM PAKAI HABIS\\nBagian: B...   \n",
       "3  [Bab: BAB II - PERIKATAN YANG LAHIR DARI KONTR...   \n",
       "4  [Bab: BAB V - JUAL BELI\\nBagian: BAGIAN 1 - Ke...   \n",
       "\n",
       "                                            response  \\\n",
       "0  Bunyi Pasal 1722: \"Jika pemberi titipan bergan...   \n",
       "1  Bunyi Pasal 1803:\\nPenerima kuasa bertanggung ...   \n",
       "2  Bunyi Pasal 1764: \"Jika ia tidak mungkin memen...   \n",
       "3  Bunyi Pasal 1337: \"suatu sebab adalah terlaran...   \n",
       "4  Bunyi Pasal 1469: \"Atas ancaman yang sama, par...   \n",
       "\n",
       "                                           reference  context_recall  \\\n",
       "0  Bab: BAB XI - PENITIPAN BARANG\\nBagian: BAGIAN...             1.0   \n",
       "1  Bab: BAB XVI - PEMBERIAN KUASA\\nBagian: BAGIAN...             1.0   \n",
       "2  Bab: BAB XIII - PINJAM PAKAI HABIS\\nBagian: BA...             1.0   \n",
       "3  Bab: BAB II - PERIKATAN YANG LAHIR DARI KONTRA...             1.0   \n",
       "4  Bab: BAB V - JUAL BELI\\nBagian: BAGIAN 1 - Ket...             1.0   \n",
       "\n",
       "   faithfulness  factual_correctness(mode=f1)  \n",
       "0           1.0                          1.00  \n",
       "1           1.0                          1.00  \n",
       "2           1.0                          1.00  \n",
       "3           1.0                          0.67  \n",
       "4           1.0                          1.00  "
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(result)\n",
    "df_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.13 ('llm_langgraph')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "563f4e1139af12a3e466c92be8b5f61db6fc37b4947f50811b94e9833745ec63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
